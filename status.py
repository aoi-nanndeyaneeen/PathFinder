import cv2
import numpy as np
import platform  # OSåˆ¤å®šç”¨ã«è¿½åŠ 
from arUco_detector import get_aruco_pose, CAMERA_MATRIX, DIST_COEFFS

class PositionTracker:
    def __init__(self):
        # --- é«˜é€ŸåŒ–ã®ãŸã‚ã®ä¿®æ­£ç®‡æ‰€ ---
        # OSã«ã‚ˆã£ã¦æœ€é©ãªãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚’æŒ‡å®šã™ã‚‹
        system_name = platform.system()
        if system_name == 'Windows':
            # Windowsã®å ´åˆã€DirectShow (CAP_DSHOW) ã‚’æŒ‡å®šã™ã‚‹ã¨éžå¸¸ã«é€Ÿããªã‚‹
            backend = cv2.CAP_DSHOW
        elif system_name == 'Linux':
            # Linux (Ubuntu/Raspberry Pi) ã®å ´åˆ
            backend = cv2.CAP_V4L2
        else:
            # Macã‚„ãã®ä»–ã®å ´åˆã€è‡ªå‹•é¸æŠž(CAP_ANY)
            backend = cv2.CAP_ANY

        print(f"ðŸ“· Camera initializing with backend: {backend} ...")

        # ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚’æŒ‡å®šã—ã¦ã‚«ãƒ¡ãƒ©ã‚’ã‚ªãƒ¼ãƒ—ãƒ³
        self.cap0 = cv2.VideoCapture(0, backend)
        self.cap2 = cv2.VideoCapture(1, backend)
        
        # è§£åƒåº¦ã‚„FPSã‚’æ˜Žç¤ºçš„ã«æŒ‡å®šã™ã‚‹ã¨å®‰å®šã™ã‚‹å ´åˆãŒã‚ã‚‹ï¼ˆå¿…è¦ã«å¿œã˜ã¦ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆè§£é™¤ï¼‰
        # self.set_camera_settings(self.cap0)
        # self.set_camera_settings(self.cap2)

        # åŸºæº–åº§æ¨™ï¼ˆãƒªã‚»ãƒƒãƒˆç”¨ã‚ªãƒ•ã‚»ãƒƒãƒˆï¼‰
        self.ref_x = 0.0
        self.ref_z = 0.0
        self.ref_yaw = 0.0
        print("âœ… Camera initialized.")

    # (ã‚ªãƒ—ã‚·ãƒ§ãƒ³) ã‚«ãƒ¡ãƒ©è¨­å®šç”¨ãƒ˜ãƒ«ãƒ‘ãƒ¼
    def set_camera_settings(self, cap):
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        cap.set(cv2.CAP_PROP_FPS, 30)

    def is_opened(self):
        return self.cap0.isOpened() and self.cap2.isOpened()

    def reset_origin(self, raw_x, raw_z, raw_yaw):
        """ä»Šã®ç”Ÿã®åº§æ¨™ã‚’åŸºæº–ç‚¹(0,0,0)ã«ã‚»ãƒƒãƒˆã™ã‚‹"""
        self.ref_x = raw_x
        self.ref_z = raw_z
        self.ref_yaw = raw_yaw
        print("ðŸ“ åº§æ¨™ãƒªã‚»ãƒƒãƒˆå®Œäº† (Origin Set)")

    def get_current_state(self):
        """
        ã‚«ãƒ¡ãƒ©ç”»åƒã‚’èª­ã¿è¾¼ã¿ã€çŠ¶æ³ã‚’è¿”ã™é–¢æ•°
        æˆ»ã‚Šå€¤: (unified_x, unified_z, unified_yaw, raw_x, raw_z, raw_yaw, frame0, frame2, is_detected)
        """
        ret0, frame0 = self.cap0.read()
        ret2, frame2 = self.cap2.read()

        if not ret0 or not ret2:
            return None, None, None, None, None, None, None, None, False

        pose0 = get_aruco_pose(frame0)
        pose2 = get_aruco_pose(frame2)

        # åˆæœŸå€¤
        unified_x = 0.0
        unified_z = 0.0
        unified_yaw = 0.0
        raw_x = 0.0
        raw_z = 0.0
        raw_yaw = 0.0
        is_detected = False

        # ä¸¡æ–¹ã®ã‚«ãƒ¡ãƒ©ã§ãƒžãƒ¼ã‚«ãƒ¼ãŒè¦‹ãˆã¦ã„ã‚‹å ´åˆã®ã¿è¨ˆç®—
        if pose0 and pose2:
            is_detected = True
            
            # --- åº§æ¨™ã®å–å¾— (Raw Data) ---
            raw_x = pose0[0]       # Cam0ã®X
            raw_z = pose2[0]       # Cam2ã®Xã‚’Zã¨ã—ã¦åˆ©ç”¨
            raw_yaw = pose0[3]     # Cam0ã®Yaw

            # --- åŸºæº–å€¤ã‹ã‚‰ã®å·®åˆ†è¨ˆç®— (Unified Data) ---
            unified_x = raw_x - self.ref_x
            unified_z = raw_z - self.ref_z
            unified_yaw = raw_yaw - self.ref_yaw

            # è§’åº¦ã®æ­£è¦åŒ– (-180 ~ 180)
            if unified_yaw > 180: unified_yaw -= 360
            elif unified_yaw <= -180: unified_yaw += 360

            # --- æç”»å‡¦ç† ---
            self._draw_marker(frame0, pose0)
            self._draw_marker(frame2, pose2)

        return unified_x, unified_z, unified_yaw, raw_x, raw_z, raw_yaw, frame0, frame2, is_detected

    def _draw_marker(self, frame, pose):
        """ãƒžãƒ¼ã‚«ãƒ¼æž ã¨è»¸ã‚’æç”»ã™ã‚‹å†…éƒ¨é–¢æ•°"""
        if pose:
            draw_info = pose[4]
            cv2.aruco.drawDetectedMarkers(frame, np.array([draw_info['corners']]), np.array([[1]]))
            cv2.drawFrameAxes(frame, CAMERA_MATRIX, DIST_COEFFS, draw_info['rvec'], draw_info['tvec'], 0.02)

    def release(self):
        self.cap0.release()
        self.cap2.release()